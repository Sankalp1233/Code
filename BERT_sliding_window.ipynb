{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT sliding window.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMD+ePJWoErQMzcDZbY7DTm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b8844ba5effe465e947f2f4223c3e876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d639171a128640babd27f1913c9937b2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_416d3ac0b40546028c41c360c81faa9f",
              "IPY_MODEL_836d5c87e2c54cd8b96f5b6f791d72c9"
            ]
          }
        },
        "d639171a128640babd27f1913c9937b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "416d3ac0b40546028c41c360c81faa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5e323b7ae6940fb9e56bca2259188f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_82fa03a6f6894bc1a65e637e4ccedb47"
          }
        },
        "836d5c87e2c54cd8b96f5b6f791d72c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d339e0b24f34da18fbbd810043afca0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00, 24.29 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48ab8789243d4b3d9f618e8a6d8c4830"
          }
        },
        "a5e323b7ae6940fb9e56bca2259188f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "82fa03a6f6894bc1a65e637e4ccedb47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d339e0b24f34da18fbbd810043afca0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48ab8789243d4b3d9f618e8a6d8c4830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "704a5bf122584e5caa459b7eb3c614e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de850740679c464e9f82a4108e0e4cfe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_154a775b8cf849509a0aa71ba05322ed",
              "IPY_MODEL_0c0cb5bd86be4ad790b9914361f7de05"
            ]
          }
        },
        "de850740679c464e9f82a4108e0e4cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "154a775b8cf849509a0aa71ba05322ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8156945443064117be403c1722e992ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89dad3f4e2db4931bb2eca4113a5c3cc"
          }
        },
        "0c0cb5bd86be4ad790b9914361f7de05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff6aa736b30f4537a14185ef4c3fd230",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/? [00:00&lt;00:00, 18.36 tables/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9914bf640e941e1bc617eaa65315460"
          }
        },
        "8156945443064117be403c1722e992ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89dad3f4e2db4931bb2eca4113a5c3cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff6aa736b30f4537a14185ef4c3fd230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9914bf640e941e1bc617eaa65315460": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sankalp1233/Code/blob/main/BERT_sliding_window.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EZewu46nHzh"
      },
      "source": [
        "squad_v2 = False\n",
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 569,
          "referenced_widgets": [
            "b8844ba5effe465e947f2f4223c3e876",
            "d639171a128640babd27f1913c9937b2",
            "416d3ac0b40546028c41c360c81faa9f",
            "836d5c87e2c54cd8b96f5b6f791d72c9",
            "a5e323b7ae6940fb9e56bca2259188f3",
            "82fa03a6f6894bc1a65e637e4ccedb47",
            "3d339e0b24f34da18fbbd810043afca0",
            "48ab8789243d4b3d9f618e8a6d8c4830",
            "704a5bf122584e5caa459b7eb3c614e6",
            "de850740679c464e9f82a4108e0e4cfe",
            "154a775b8cf849509a0aa71ba05322ed",
            "0c0cb5bd86be4ad790b9914361f7de05",
            "8156945443064117be403c1722e992ba",
            "89dad3f4e2db4931bb2eca4113a5c3cc",
            "ff6aa736b30f4537a14185ef4c3fd230",
            "e9914bf640e941e1bc617eaa65315460"
          ]
        },
        "id": "mLVpaVzwJN7o",
        "outputId": "dafd6c5f-e9f4-4864-93c0-82270bea1a7f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() \n",
        "filename = \"Spark_QA.txt\"\n",
        "new_file = uploaded[filename].decode(\"utf-8\")\n",
        "sentences = new_file.split('\\n')\n",
        "context = []\n",
        "questions = []\n",
        "count = 0\n",
        "for i in sentences:\n",
        "    if count % 2 == 1:\n",
        "        context.append(i)\n",
        "    else:\n",
        "      questions.append(i)\n",
        "    count += 1\n",
        "import pandas as pd\n",
        "questions = pd.DataFrame(questions)\n",
        "questions.columns = [\"questions\"]\n",
        "context = pd.DataFrame(context)\n",
        "context.columns = [\"context\"]\n",
        "horizontal_stack = pd.concat([questions, context], axis=1)\n",
        "horizontal_stack.columns = ['question','context']\n",
        "horizontal_stack = pd.DataFrame(horizontal_stack)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(horizontal_stack,test_size = 0.05)\n",
        "!pip3 install datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "new_train_df = pd.DataFrame(train_df)\n",
        "# new_train_df.to_csv(r'C:\\Desktop\\Sonny_Simons Fou ndation\\train.csv', index = False, header=True)\n",
        "new_val_df = pd.DataFrame(val_df)\n",
        "# new_val_df.to_csv(r'C:\\Desktop\\Sonny_Simons Fou ndation\\test.csv', index = False, header=True)\n",
        "vertical_stack = pd.concat([new_train_df, new_val_df], axis=0)\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "new_train_df.to_csv('train.csv')\n",
        "new_val_df.to_csv('test.csv')\n",
        "from datasets import load_dataset\n",
        "train_test_csv_dataset = load_dataset('csv', data_files={'train': 'train.csv',\n",
        "                                              'test': 'test.csv'})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d06c60a2-5351-4e0a-9e12-ce3b7a13eed1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d06c60a2-5351-4e0a-9e12-ce3b7a13eed1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Spark_QA.txt to Spark_QA (1).txt\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.10.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-22f222903204abc1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n",
            "Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-22f222903204abc1/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8844ba5effe465e947f2f4223c3e876",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "704a5bf122584e5caa459b7eb3c614e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rDataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-22f222903204abc1/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wEn4M3kOfN5",
        "outputId": "a560c831-c5e6-4cad-9cfd-635e908bfb7d"
      },
      "source": [
        "# !pip3 install string\n",
        "def chatbot():\n",
        "    model_checkpoint = \"distilbert-base-uncased\"\n",
        "    from transformers import AutoTokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "    question = input(\"Ask a question: \")\n",
        "    from string import ascii_letters\n",
        "    question = ''.join([letter for letter in question if letter in ascii_letters])\n",
        "    answer = []\n",
        "    for i in range(len(train_test_csv_dataset[\"train\"])):\n",
        "        example = train_test_csv_dataset[\"train\"][i]\n",
        "        example['question'] = ''.join([letter for letter in example['question'] if letter in ascii_letters])\n",
        "        # print(example['question'])\n",
        "        if question.lower().replace(\" \", \"\") == example['question'].lower().replace(\" \", \"\"):\n",
        "           tokenized_example = tokenizer(\n",
        "                               question,\n",
        "                               example[\"context\"],\n",
        "                               max_length=len(example[\"context\"]) + len(example['question']),\n",
        "                               truncation=\"only_second\",\n",
        "                               return_overflowing_tokens=True,\n",
        "                               return_offsets_mapping=True,\n",
        "                               stride = 128)\n",
        "           answers = example[\"context\"]\n",
        "           start_char = 0\n",
        "           end_char = start_char + len(answers)\n",
        "           sequence_ids = tokenized_example.sequence_ids()\n",
        "           # Start token index of the current span in the text.\n",
        "           token_start_index = 0\n",
        "           while sequence_ids[token_start_index] != 1:\n",
        "                 token_start_index += 1\n",
        "           # End token index of the current span in the text.\n",
        "           token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "           while sequence_ids[token_end_index] != 1:\n",
        "                 token_end_index -= 1\n",
        "          # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "           offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "           if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "             # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "             # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "              while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "              start_position = token_start_index - 1\n",
        "              while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "              end_position = token_end_index + 1\n",
        "              answer.append(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
        "    for i in range(len(train_test_csv_dataset[\"test\"])):\n",
        "        example = train_test_csv_dataset[\"test\"][i]\n",
        "        example['question']= ''.join([letter for letter in example['question'] if letter in ascii_letters])\n",
        "        # print(example['question'])\n",
        "        if question.lower().replace(\" \", \"\") == example['question'].lower().replace(\" \", \"\"):\n",
        "           tokenized_example = tokenizer(\n",
        "                                question,\n",
        "                                example[\"context\"],\n",
        "                                max_length= len(example[\"context\"]) + len(example['question']),\n",
        "                                truncation=\"only_second\",\n",
        "                                return_overflowing_tokens=True,\n",
        "                                return_offsets_mapping=True,\n",
        "                                stride = 128)\n",
        "           answers = example[\"context\"]\n",
        "           start_char = 0\n",
        "           end_char = start_char + len(answers)\n",
        "           sequence_ids = tokenized_example.sequence_ids()\n",
        "           # Start token index of the current span in the text.\n",
        "           token_start_index = 0\n",
        "           while sequence_ids[token_start_index] != 1:\n",
        "                 token_start_index += 1\n",
        "           # End token index of the current span in the text.\n",
        "           token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "           while sequence_ids[token_end_index] != 1:\n",
        "                 token_end_index -= 1\n",
        "           # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "           offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "           if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "               # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "               # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "              while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "              start_position = token_start_index - 1\n",
        "              while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "              end_position = token_end_index + 1\n",
        "              answer.append(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
        "    TDNA_string = \"What can my TDNA do?\"\n",
        "    DNA_string = \"What can we do from DNA with thousands of families across the country?\"\n",
        "    gene_string = \"What makes it easier to spot differences in genes?\"\n",
        "    weather_string = \"What is the weather today?\"\n",
        "    last_name_string = \"What is my last name?\"\n",
        "    first_name_string = \"What is my first name?\"\n",
        "    children_and_dep_adults_string = \"To participate in SPARK, what do children ages 10 through 17 and dependent adults need to do?\"\n",
        "    saliva_collection_string = \"What is saliva collection used for?\"\n",
        "    military_string = \"If I am an individual who is in the military overseas what address should I use for registration?\"\n",
        "    address_string = \"How do I make changes to my address?\"\n",
        "    join_SPARK_string = \"What happens when you join SPARK?\"\n",
        "    NDAR_full_string = \"What is National Database for Autism Research?\"\n",
        "    NDAR_string = \"What is NDAR?\"\n",
        "    NDAR_full_string2 = \"What is the National Database for Autism Research?\"\n",
        "    NDAR_string2 = \"What is the NDAR?\"\n",
        "    Research_data_string = \"What happens before any of my research data is shared for other autism research?\"\n",
        "    Sequencing_data_string = \"Where is sequencing data stored?\"\n",
        "    DNA_sequencing_string = \"What portion of DNA does SPARK look at for DNA sequencing?\"\n",
        "    Outside_researcher_string = \"What must an outside researcher do before they are allowed to access SPARK's DNA database?\"\n",
        "    contact_info_string = \"Will Spark share my contact information?\"\n",
        "    TDNA_string = ''.join([letter for letter in TDNA_string if letter in ascii_letters])\n",
        "    DNA_string = ''.join([letter for letter in DNA_string if letter in ascii_letters])\n",
        "    gene_string = ''.join([letter for letter in gene_string if letter in ascii_letters])\n",
        "    weather_string = ''.join([letter for letter in weather_string if letter in ascii_letters])\n",
        "    last_name_string = ''.join([letter for letter in last_name_string if letter in ascii_letters])\n",
        "    first_name_string = ''.join([letter for letter in first_name_string if letter in ascii_letters])\n",
        "    children_and_dep_adults_string = ''.join([letter for letter in children_and_dep_adults_string if letter in ascii_letters])\n",
        "    saliva_collection_string = ''.join([letter for letter in saliva_collection_string if letter in ascii_letters])\n",
        "    military_string = ''.join([letter for letter in military_string if letter in ascii_letters])\n",
        "    address_string = ''.join([letter for letter in address_string if letter in ascii_letters])\n",
        "    join_SPARK_string = ''.join([letter for letter in join_SPARK_string if letter in ascii_letters])\n",
        "    NDAR_full_string = ''.join([letter for letter in NDAR_full_string if letter in ascii_letters])\n",
        "    NDAR_string = ''.join([letter for letter in NDAR_string if letter in ascii_letters])\n",
        "    NDAR_full_string2 = ''.join([letter for letter in NDAR_full_string2 if letter in ascii_letters])\n",
        "    NDAR_string2 = ''.join([letter for letter in NDAR_string2 if letter in ascii_letters])\n",
        "    Research_data_string = ''.join([letter for letter in Research_data_string if letter in ascii_letters])\n",
        "    Sequencing_data_string = ''.join([letter for letter in Sequencing_data_string if letter in ascii_letters])\n",
        "    DNA_sequencing_string = ''.join([letter for letter in DNA_sequencing_string if letter in ascii_letters])\n",
        "    Outside_researcher_string = ''.join([letter for letter in Outside_researcher_string if letter in ascii_letters])\n",
        "    contact_info_string = ''.join([letter for letter in contact_info_string if letter in ascii_letters])\n",
        "    if   len(answer)!=0:\n",
        "         print(' '.join([str(elem) for elem in answer]))\n",
        "    elif question.lower().replace(\" \", \"\") == TDNA_string.lower().replace(\" \", \"\"):\n",
        "         print('spark the next genetic discovery')\n",
        "    elif question.lower().replace(\" \", \"\") == DNA_string.lower().replace(\" \", \"\"):\n",
        "         print('learn more about genes related to autism and find new ones')\n",
        "    elif question.lower().replace(\" \", \"\") == gene_string.lower().replace(\" \", \"\"):\n",
        "         print('DNA from thousands of families across the country')\n",
        "    elif question.lower().replace(\" \", \"\") == weather_string.lower().replace(\" \", \"\"):\n",
        "         print('This is not related to spark please ask another question')\n",
        "    elif question.lower().replace(\" \", \"\") == last_name_string.lower().replace(\" \", \"\"):\n",
        "         print(\"This is not related to spark please ask another question\")\n",
        "    elif question.lower().replace(\" \", \"\") == first_name_string.lower().replace(\" \", \"\"):\n",
        "         print(\"This is not related to spark please ask another question\")\n",
        "    elif question.lower().replace(\" \",\"\") == children_and_dep_adults_string.lower().replace(\" \",\"\"):\n",
        "         print(\"asked to assent, if they are capable. Assent is a child's or dependent's agreement that he or she is willing to participate in research.\")\n",
        "    elif question.lower().replace(\" \",\"\") == saliva_collection_string.lower().replace(\" \",\"\"):\n",
        "         print(\"It is a common method for research ranging from large scientific studies to individual personalized medicine tests.\")\n",
        "    elif question.lower().replace(\" \",\"\") == military_string.lower().replace(\" \",\"\"):\n",
        "         print(\"Use your current FPO or APO address.\")\n",
        "    elif question.lower().replace(\" \",\"\") == address_string.lower().replace(\" \",\"\"):\n",
        "         print(\"You can do so by visiting your SPARK dashboard.\")\n",
        "    elif question.lower().replace(\" \",\"\") == join_SPARK_string.lower().replace(\" \",\"\"):\n",
        "         print(\"When you join SPARK, you allow the Simons Foundation Autism Research Initiative (SFARI) to share your research data with the National Database for Autism Research (NDAR).\")\n",
        "    elif question.lower().replace(\" \",\"\") == NDAR_full_string.lower().replace(\" \",\"\") or question.lower().replace(\" \",\"\") == NDAR_string.lower().replace(\" \",\"\") or question.lower().replace(\" \",\"\") == NDAR_string2.lower().replace(\" \",\"\") or question.lower().replace(\" \",\"\") == NDAR_full_string2.lower().replace(\" \",\"\"):\n",
        "         print(\"NDAR is a central research data source for autism researchers from around the country. Data in NDAR is stored without any information that could identify you.\")\n",
        "    elif question.lower().replace(\" \",\"\") == Research_data_string.lower().replace(\" \",\"\"):\n",
        "         print(\"all information that could identify you is replaced with a global unique identifier (GUID). GUIDs allow researchers to share research data about you without exposing anything that could identify you.\")\n",
        "    elif question.lower().replace(\" \",\"\") == Sequencing_data_string.lower().replace(\" \",\"\"):\n",
        "         print(\"All sequencing data is stored securely in the SPARK database.\")\n",
        "    elif question.lower().replace(\" \",\"\") == DNA_sequencing_string.lower().replace(\" \",\"\"):\n",
        "         print(\"SPARK only looks at the portion of DNA that codes for proteins, because most genetic differences related to autism are found in this part of an individual’s DNA.\")\n",
        "    elif question.lower().replace(\" \",\"\") == Outside_researcher_string.lower().replace(\" \",\"\"):\n",
        "         print(\"Outside researchers must go through an approval process before they are allowed to access SPARK’s DNA database.\")\n",
        "    elif question.lower().replace(\" \",\"\") == contact_info_string.lower().replace(\" \",\"\"):\n",
        "         print(\"Your contact information will not be shared with researchers through SPARK’s research matching program unless you give us permission.\")\n",
        "    else:\n",
        "      print(\"Please email info@SPARKforAutism.org\")\n",
        "chatbot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ask a question: Will you share my data?\n",
            "Please email info@SPARKforAutism.org\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "4_GEKkn75SYE",
        "outputId": "a23f0e73-d929-4135-fdaf-071cae4c0a17"
      },
      "source": [
        "\"\"\"\n",
        "Simple QA dialogue manager\n",
        "\"\"\"\n",
        "!pip3 install git+https://github.com/spokestack/wikiqa-python\n",
        "# cd wikiqa-python\n",
        "import tensorflow as tf\n",
        "!pip3 install mediawiki\n",
        "from mediawiki import MediaWiki\n",
        "from spokestack.nlu.result import Result\n",
        "from spokestack.nlu.tflite import TFLiteNLU\n",
        "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering\n",
        "\n",
        "\n",
        "class DialogueManager:\n",
        "    \"\"\" Simple Question Answering Dialogue Manager \"\"\"\n",
        "\n",
        "    def __init__(self, log_path: str, base_model: str) -> None:\n",
        "        self._wiki = MediaWiki()\n",
        "        self._nlu = TFLiteNLU(log_path)\n",
        "        self._tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "        self._answerer = TFAutoModelForQuestionAnswering.from_pretrained(base_model)\n",
        "\n",
        "    def __call__(self, utterance: str) -> str:\n",
        "        result = self._nlu(utterance)\n",
        "        if result.intent == \"ask.question\":\n",
        "            return self._answer(result)\n",
        "        elif result.intent == \"greet\":\n",
        "            return self.greet()\n",
        "        elif result.intent == \"command.exit\":\n",
        "            return self.exit()\n",
        "        elif result.intent == \"request.help\":\n",
        "            return self.help()\n",
        "        else:\n",
        "            return self.fallback()\n",
        "\n",
        "    def _answer(self, result: Result) -> str:\n",
        "        if result.slots:\n",
        "            # get the tagged entity for page search\n",
        "            entity = result.slots.get(\"entity\").get(\"raw_value\")\n",
        "            # perform the search to find the wikipedia page\n",
        "            entity = self._wiki.search(entity)[0]\n",
        "            # get the page content to feed as context to the qa model\n",
        "            passage = self._wiki.page(entity, auto_suggest=False).content\n",
        "            # prepare qa model inputs\n",
        "            inputs = self._tokenizer(\n",
        "                result.utterance,\n",
        "                passage,\n",
        "                return_tensors=\"tf\",\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "            )\n",
        "            # compute answer span\n",
        "            start_scores, end_scores = self._answerer(inputs)\n",
        "            start, end = tf.argmax(start_scores, -1)[0], tf.argmax(end_scores, -1)[0]\n",
        "            # prepare the passage ids for slicing\n",
        "            tokens = self._tokenizer.convert_ids_to_tokens(\n",
        "                (inputs[\"input_ids\"].numpy()[0])\n",
        "            )\n",
        "            # retrieve only the answer from the passage\n",
        "            answer = self._tokenizer.convert_tokens_to_string(tokens[start : end + 1])\n",
        "            return answer\n",
        "        return \"I don't have an answer for that\"\n",
        "\n",
        "    @staticmethod\n",
        "    def greet() -> str:\n",
        "        return \"Hello, Ask me anything\"\n",
        "\n",
        "    @staticmethod\n",
        "    def exit() -> str:\n",
        "        return \"Goodbye\"\n",
        "\n",
        "    @staticmethod\n",
        "    def fallback() -> str:\n",
        "        return (\n",
        "            \"I'm having trouble understanding your request, could you please \"\n",
        "            \"repeat it\"\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def help() -> str:\n",
        "        return \"Ask a question like, how long is the amazon river?\n",
        "manager = TextToSpeechManager(TextToSpeechClient(KEY_ID, KEY_SECRET), PyAudioOutput())\n",
        "manager.synthesize(\"hello, world\", \"text\", \"demo-male\")\n",
        "@pipeline.event\n",
        "def on_recognize(context):\n",
        "    pipeline.pause()\n",
        "    answer = dialogue_manager(context.transcript)\n",
        "    manager.synthesize(answer, \"text\", \"demo-male\")\n",
        "    pipeline.resume()\n",
        "\n",
        "\n",
        "manager.synthesize(dialogue_manager.greet(), \"text\", \"demo-male\")\n",
        "pipeline.start()\n",
        "pipeline.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-7dfdf7f9c056>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    cd wikiqa-python\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikO0Dbl_KZ8O",
        "outputId": "0de7cc6b-0cbe-45e5-acd7-dc4cd64a7f11"
      },
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
        "for i, example in enumerate(train_test_csv_dataset[\"train\"]):\n",
        "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
        "        break\n",
        "example = train_test_csv_dataset[\"train\"][i]\n",
        "print(i)\n",
        "print(train_test_csv_dataset[\"train\"][i]['question'])\n",
        "tokenized_example = tokenizer(\n",
        "    \"What if I or my child can’t spit?\",\n",
        "    # example[\"question\"],\n",
        "    example[\"context\"],\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    stride = doc_stride\n",
        ")\n",
        "answers = example[\"context\"]\n",
        "start_char = 0\n",
        "end_char = start_char + len(answers)\n",
        "sequence_ids = tokenized_example.sequence_ids()\n",
        "# Start token index of the current span in the text.\n",
        "token_start_index = 0\n",
        "while sequence_ids[token_start_index] != 1:\n",
        "    token_start_index += 1\n",
        "\n",
        "# End token index of the current span in the text.\n",
        "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "while sequence_ids[token_end_index] != 1:\n",
        "    token_end_index -= 1\n",
        "\n",
        "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "        token_start_index += 1\n",
        "    start_position = token_start_index - 1\n",
        "    while offsets[token_end_index][1] >= end_char:\n",
        "        token_end_index -= 1\n",
        "    end_position = token_end_index + 1\n",
        "    print(start_position, end_position)\n",
        "else:\n",
        "    print(\"The answer is not in this feature.\")\n",
        "print(example['question'])\n",
        "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72\n",
            "What if I or my child can’t spit?\n",
            "13 90\n",
            "What if I or my child can’t spit?\n",
            "if you or your child are unable to spit, you can use the sponges that are included with each saliva kit. caregivers can collect the sample by sponging the inside of the person ’ s cheek and pressing the sponge against the notch of the funnel so that the saliva will flow into the tube. you can find video resources that will further explain the saliva collection process here.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttX6PLT0UYok"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "omVrKSvYoAvV",
        "outputId": "f7921e60-f205-4f6c-b2db-1252384db2da"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload() \n",
        "filename = \"context.txt\"\n",
        "new_file = uploaded[filename].decode(\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9e1b274e-b519-4ad2-a607-a325dffeb7c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9e1b274e-b519-4ad2-a607-a325dffeb7c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving context.txt to context (1).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw3eID5an84C",
        "outputId": "20598532-0c7a-4e17-9037-2855c46e78d8"
      },
      "source": [
        "!pip3 install transformers\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenized_example = tokenizer(\n",
        "    \"What is the purpose of Spark?\",\n",
        "    new_file,\n",
        "    max_length=max_length,\n",
        "    truncation=\"only_second\",\n",
        "    return_overflowing_tokens=True,\n",
        "    return_offsets_mapping=True,\n",
        "    stride=doc_stride\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-AlPUeyo8SI",
        "outputId": "eba0ad25-2903-4919-9246-e8e34eb6b3be"
      },
      "source": [
        "for x in tokenized_example[\"input_ids\"]:\n",
        "    print(tokenizer.decode(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] what is the purpose of spark? [SEP] the purpose of spark is to help scientists find and better understand the potential causes of autism. as part of this effort, we study dna from people with autism and from their family members who may or may not have autism. we also study information about their health and things that can impact health like behavior and lifestyle. to succeed, spark needs many thousands of people with autism and their families to join. what we collect and learn will be shared with many autism researchers to help speed up the progress of autism research. you should take part in spark to help shape the future of autism research. your tdna could spark the next genetic discovery. with dna from thousands of families across the country, we will be able to learn more about genes that may be related to autism and discover new ones. in return, you will be able to get updates on the latest research, join other autism research studies, find possible genetic causes of autism in your own family, and power future autism research for years to come. the people who can take part in spark if you or your dependent ( s ) : have a diagnosis of autism spectrum disorder ( asd ). this can include asperger syndrome, autism / autistic disorder, and pervasive developmental disorder not otherwise specified ( pdd - nos ). currently live in the u. s. or are serving in the u. s military abroad. can read and understand english. all ages are welcome! at this time individuals who are eligible to register in spark include : the legal guardian of a dependent or dependents with a professional diagnosis of asd. guardians can register on behalf of themselves and their dependent ( s ). in relevant circumstances, legal guardians can invite biological parents of their dependent ( s ) to join if they are able / choose to. an independent adult with a professional diagnosis. adults can register for themselves and can invite biological parents and full adult siblings to join as well. they can also register their own dependent ( s ), if applicable, during their registration. please note : if you have an eligible diagnosis ( see above ), you can take part in spark even if your siblings or parents don't. if your child has autism the other family members who can join spark include : both of the child ( ren ) as birth parents. any additional children with a formal asd diagnosis. they must be under the age of 18 or your legally dependent adult child. one full biological sibling of the child with autism who does not have an asd diagnosis can be [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] biological parents and full adult siblings to join as well. they can also register their own dependent ( s ), if applicable, during their registration. please note : if you have an eligible diagnosis ( see above ), you can take part in spark even if your siblings or parents don't. if your child has autism the other family members who can join spark include : both of the child ( ren ) as birth parents. any additional children with a formal asd diagnosis. they must be under the age of 18 or your legally dependent adult child. one full biological sibling of the child with autism who does not have an asd diagnosis can be added. however, parents who have more than one child with asd may add all siblings without autism. if your child is adopted you can still take part in spark. for more, see : who can take part in spark? a¢a ‚ ¬a and if my child has autism, who else in the family can take part in spark? you can enroll in spark if you have yes. families who have already completed clinical genetic testing are encouraged to participate in spark and complete our saliva collection process if they are otherwise eligible for our study. participating in spark allows their de - identified information to become available to top researchers who are moving autism research forward and helping to find answers for the community at large. participating also means that the family will have the opportunity to take part in additional research opportunities if they are interested. such opportunities may become available through sparks research match program. you can read more about sparks research match program here. if earlier genetic testing for autism found nothing then you and your child can still take part in spark. new genes and genetic changes related to autism are found on a regular basis, and one of sparks goals is to discover more of these. you can stop taking part in spark at any time. your familya€™s privacy is a top priority of our study, and participation in spark is completely voluntary. you need only send an email to info @ sparkforautism. org if you would like to withdraw. spark needs to study so many people since the more people who enroll in spark, the more genes and genetic changes related to autism we are likely to discover. when we compare the dna of thousands of people, we can find differences between individuals. sometimes these differences are related to autism, and other times they are not. spark aims to enroll 50, 000 families affected by autism in order to move autism research forward more quickly. spark will [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP]€™s privacy is a top priority of our study, and participation in spark is completely voluntary. you need only send an email to info @ sparkforautism. org if you would like to withdraw. spark needs to study so many people since the more people who enroll in spark, the more genes and genetic changes related to autism we are likely to discover. when we compare the dna of thousands of people, we can find differences between individuals. sometimes these differences are related to autism, and other times they are not. spark aims to enroll 50, 000 families affected by autism in order to move autism research forward more quickly. spark will share its findings. spark data will be shared with the entire autism research community ( doctors, experts and researchers ) so that they can study and learn from it. we are also publishing findings in scientific journals and returning information to our participants via study reports. spark is sponsored by the simons foundation autism research initiative ( sfari ). sfaria€™s mission is to improve the understanding, diagnosis and treatment of autism spectrum disorder ( asd ) by funding cutting - edge research of the highest quality and significance. for more information on sfari, please visit https : / / sfari. org /. spark clinical sites are a network of 25 autism research centers at universities and hospitals throughout the country that have partnered with spark. these sites help educate their local communities about spark, enroll new participants, and run autism research studies of their own. click here to learn more and to see if therea€™s a spark clinical site near you! in order to join spark you have to enroll online at www. sparkforautism. org. it will involve several steps. each independent adult participant must have their own email address. you can start and stop the registration process at any time, and your information will be saved along the way. you also have the option of completing your registration at one of our 25 clinical sites across the country. click here to see if therea€™s a site near you! also, when you enrolled in spark, we asked if we could contact you about other autism research that may be relevant to you or your family. if you agreed, you may be invited to join these other studies via email. participation in these studies is completely voluntary. there is no cost to join spark. you will never be asked to give money as part of this project. the time commitment for enrolling online takes between 15 and 30 minutes. you can [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] way. you also have the option of completing your registration at one of our 25 clinical sites across the country. click here to see if therea€™s a site near you! also, when you enrolled in spark, we asked if we could contact you about other autism research that may be relevant to you or your family. if you agreed, you may be invited to join these other studies via email. participation in these studies is completely voluntary. there is no cost to join spark. you will never be asked to give money as part of this project. the time commitment for enrolling online takes between 15 and 30 minutes. you can start and stop the process at any time, and your information will be saved along the way. for the saliva sample collection, producing enough saliva can take anywhere from 15 minutes to an hour. if you forgot your login information then : your username is the email address you used when you registered with spark. if you have forgotten your password, you can reset it by clicking here or selecting login on the sparkforautism. org home page. on the login page, click on a¢a ‚ ¬a “ reset password. to invite other people during registration, you may be prompted to invite biological relatives like parents or siblings via email. you can also invite other family members to participate after youve registered by using the invitation tool on your dashboard. we will let you know when other invitation features become available. please note : we know that each family in our community is different from the next, and we don't expect anyone to invite family members or relatives that they know are either unable to or uninterested in participating. if you invited someone to participate in spark and they haven't joined yet, please double - check to make sure you used the correct email address during the invitation process and ask them to check that the invitation did not go into a spam folder. if there is a problem, you can resend an invitation from your study dashboard. the spark study team will send up to three reminder messages to individuals who were invited to join spark by another participant. after that, the spark study team will make no further attempts to reach that individual. if you or your child are unable to spit, you can use the sponges that are included with each saliva kit. caregivers can collect the sample by sponging the inside of the persons cheek and pressing the sponge against the notch of the funnel so that the saliva will flow into [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] check that the invitation did not go into a spam folder. if there is a problem, you can resend an invitation from your study dashboard. the spark study team will send up to three reminder messages to individuals who were invited to join spark by another participant. after that, the spark study team will make no further attempts to reach that individual. if you or your child are unable to spit, you can use the sponges that are included with each saliva kit. caregivers can collect the sample by sponging the inside of the persons cheek and pressing the sponge against the notch of the funnel so that the saliva will flow into the tube. you can find video resources that will further explain the saliva collection process here. the surveys that appear on the participant dash board is to collect medical and behavioral information. the number and types of surveys that you receive on your study dashboard will vary from person to person. the number and types of surveys you will be asked to complete depend on a number of factors, such as whether or not the individual has an asd diagnosis and the individuals age. none of the surveys on your study dashboard are required, but we are grateful when you complete them. they will help us learn much more. only the primary account holders and / or invited family members with an asd diagnosis will receive surveys. for example, if you invite your child's biological parent to join, they will not be asked to complete any surveys on themselves or their dependents unless they have an asd diagnosis. the surveys help us collect information about : other medical conditions. behavior. social and physical development. any services received. family medical history. spark will tell you about results from surveys you fill out. while the results don't represent a clinical evaluation, it is our hope that participants find value in survey results. for example, if a family's survey results show that an individual has a lot of concerns about a family member, the individual could talk to their doctor, school district, etc., and perhaps even use the results as a starting place for that conversation. by joining spark, you will have the chance to learn about and participate in other studies led by autism researchers from around the world. we call this program research match. for these studies, you will only be contacted if you or your family meet the enrollment criteria. you don't have to take part in any of these studies. it is your choice. if you decide not to join one study, it will not prevent you [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] survey results show that an individual has a lot of concerns about a family member, the individual could talk to their doctor, school district, etc., and perhaps even use the results as a starting place for that conversation. by joining spark, you will have the chance to learn about and participate in other studies led by autism researchers from around the world. we call this program research match. for these studies, you will only be contacted if you or your family meet the enrollment criteria. you don't have to take part in any of these studies. it is your choice. if you decide not to join one study, it will not prevent you from joining others. studies may take place online, over the phone, or in person. they range in topics from genetics to behavior interventions. our genes contain the instructions, or code, that tell our cells how to grow, develop and work. “ genetic difference ” refers to a change in a gene. these differences can range from being harmful to helpful. some can have no effect. once our lab receives a family ’ s samples, we look for genetic differences that are definitively linked to autism. if such changes are found and confirmed, the family is contacted about those results. spark will return the genetic result either through a spark genetic counselor or through the family ’ s own medical provider. since new autism genes are discovered every year, each family ’ s genes will be re - analyzed every year and rechecked for results. not everyone in spark will receive genetic results. because spark is a research study, our genetic analysis is not like a clinical genetic test or commercial sequencing service. spark provides genetic results in the form of a clinical report only if we discover a genetic change associated with autism. not everyone in spark will have genetic findings linked to autism. based on what we know today about genes that are linked to autism, spark scientists expect to find a genetic difference linked to autism in 5 % to 10 % of people in the study. this number will increase as we learn more about autism and identify more genes that are linked to autism. there is also a chance that we will find genes linked to autism in your sample only after we have studied genes from many other families and compared them with yours. in this case, it could be years before there are results to return. keep in mind that genes are not the only cause of autism, so not all people with autism will have a genetic difference. spark can collect an individual ’ s genetic information from a small sample of [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] scientists expect to find a genetic difference linked to autism in 5 % to 10 % of people in the study. this number will increase as we learn more about autism and identify more genes that are linked to autism. there is also a chance that we will find genes linked to autism in your sample only after we have studied genes from many other families and compared them with yours. in this case, it could be years before there are results to return. keep in mind that genes are not the only cause of autism, so not all people with autism will have a genetic difference. spark can collect an individual ’ s genetic information from a small sample of saliva. we ’ ll mail a saliva collection kit to your home. you can either spit directly into the tube or use the sponges provided in the kit to collect saliva. we know the process of spitting can be unpleasant or hard for many people with autism. our hope is that giving saliva will be simpler than giving blood. we are working on providing alternative methods to collect dna, and we will contact the relevant participants when these become available. once a saliva sample arrives at the lab, it goes through processing. during this stage, the lab makes sure the sample can be used. for example, they check to see if there is enough dna in the saliva for it to be usable. after processing, the sample is stored until we send it out for sequencing. we don't sequence samples as they come in. instead, for logistical reasons, we wait until we have large batches of samples ready. storage does not affect the integrity of the dna. during sequencing, we look for genetic differences that are definitively linked to autism. if such changes are found and confirmed, the family is contacted regarding those results. it can take many months to study genes and confirm findings. if we find genes linked to autism in your sample, it will be at least one year from the date we get your sample before the results will be ready to share. when spark has a genetic result to return to a family, the primary account holder is contacted by email. the family can choose if they would like to receive the result through a spark genetic counselor or through their own medical provider. for more, see “ can having genes linked to autism affect my health insurance coverage? ” spark will very rarely tell us about genetic differences not related to autism. in almost all cases, the genetic results we return will be related to autism. if we do return a result unrelated to autism, we will do [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] will be at least one year from the date we get your sample before the results will be ready to share. when spark has a genetic result to return to a family, the primary account holder is contacted by email. the family can choose if they would like to receive the result through a spark genetic counselor or through their own medical provider. for more, see “ can having genes linked to autism affect my health insurance coverage? ” spark will very rarely tell us about genetic differences not related to autism. in almost all cases, the genetic results we return will be related to autism. if we do return a result unrelated to autism, we will do so based on current recommendations from the american college of medical genetics. studying genes has shown that genetic differences play a big role in autism. there are likely hundreds of genes involved in autism, and while some of these genes are already known, very large studies like spark can help find others. learning about the genetic causes of autism will help us find potential treatments and preventive measures for things that are common within subtypes of autism, like digestive issues and seizures. since everyone has different genes, some treatments may work well for one person while other treatments may work better for someone else. in the future, treatment will likely be tailored based on your or your child ’ s particular causes of autism. if there is no history of autism in your family, then your childs autism could come from different types of genetic changes can contribute to autism. in some cases, genetic changes are passed down ( inherited ) from parents to their children. in other cases, a random change takes place in the sperm or egg because the process of copying dna is not perfect. this change to the genetic code is considered a “ de novo ” ( new ) change. studying genes can help us find changes linked to autism no matter when they take place. knowing that you or your child has genes linked to autism may be of help : when there is an opportunity to take part in research or clinical trials matching your results. when you want to connect with other people or families who share the same diagnosis. if you or other family members want to know if you or they have a higher likelihood of having a future child with autism. we need saliva from multiple family members as we are more likely to find clues about a person ’ s autism when we can also study saliva samples from their biological parents and full biological brothers or sisters. family members share many genes. comparing samples from family members makes it easier for us [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] that you or your child has genes linked to autism may be of help : when there is an opportunity to take part in research or clinical trials matching your results. when you want to connect with other people or families who share the same diagnosis. if you or other family members want to know if you or they have a higher likelihood of having a future child with autism. we need saliva from multiple family members as we are more likely to find clues about a person ’ s autism when we can also study saliva samples from their biological parents and full biological brothers or sisters. family members share many genes. comparing samples from family members makes it easier for us to spot differences in genes. under the federal genetic information nondiscrimination act ( gina ), having genes linked to autism should not affect your existing health coverage or whether you qualify for health coverage. to learn more, please visit the gina website here. yes when studying genes we can tell from saliva samples whether people are related. however, if we find that someone is not the biological parent, we will not share this information with you or anyone else. you can find copies of your signed consent forms on your study dashboard under “ my documents. ” if you would like to change your consents or assents, please contact us at info @ sparkforautism. org. assent is a child ’ s or dependent ’ s agreement that he or she is willing to participate in research. assent is used with people who are dependent or are too young to give informed consent. assent is needed if they are able to understand the research, its expected risks and possible benefits, and the activities expected of them as subjects. to receive assent from your child or dependent, you must explain this information and ask if he or she agrees. if the child gives assent, informed consent must also be obtained from the person ’ s parent or guardian. to participate in spark, children ages 10 through 17 and dependent adults are asked to assent, if they are capable. yes you can still participate in spark and contribute behavioral data without consenting to submit saliva and share your genetic data with researchers. no. if you don't consent to share your genetic data with researchers, we will not send a saliva collection kit to you. therefore, we will not have a saliva sample to analyze in order to send you results. spark is very thankful for our active community of participants! to express our gratitude, we issue amazon. com gift card codes to participants who complete certain tasks. your amazon. com [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP]. to participate in spark, children ages 10 through 17 and dependent adults are asked to assent, if they are capable. yes you can still participate in spark and contribute behavioral data without consenting to submit saliva and share your genetic data with researchers. no. if you don't consent to share your genetic data with researchers, we will not send a saliva collection kit to you. therefore, we will not have a saliva sample to analyze in order to send you results. spark is very thankful for our active community of participants! to express our gratitude, we issue amazon. com gift card codes to participants who complete certain tasks. your amazon. com gift card code will be sent to you in the form of an alphanumeric code to use toward purchases on amazon. com and will no longer appear on your dashboard. you will receive this code via email. saliva donation : within a few weeks of receiving adequate saliva samples from a family, the primary account holder will be issued up to $ 50 in amazon. com gift card codes. the $ 50 is issued per family ( including invited participants ), rather than per participant. $ 50 is the maximum amount of gift codes a participating family is eligible to receive in recognition of saliva sample donation. survey rounds : within a few weeks of completing all round 2 surveys, the primary account holder will be issued a $ 25 amazon. com gift card code. other study opportunities : if you sign up for more research studies in the future, such as through our research matching program, there may be additional compensation. amazon. com gift card codes for participation in spark are provided per family rather than per individual enrolled. they are emailed to the primary account holder. your amazon. com gift card code will arrive via email within a few weeks of your completing certain activities. we appreciate your patience! saliva donation : it may take several weeks for us to receive your kits and confirm that the samples can be analyzed. your gift code will be issued within a few weeks of confirming receipt of an adequate saliva sample or samples. you can track the progress of your sample ( s ) on your dashboard. survey rounds : round 2 survey gift codes are issued and emailed within a few weeks of completion of all assigned surveys. if it has been a few weeks, and my amazon. com gift card code still has not arrived then please first check your spark dashboard for any updates on the status of your amazon. com gift card code. please email info @ sparkforautism. org if you have additional [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] receive your kits and confirm that the samples can be analyzed. your gift code will be issued within a few weeks of confirming receipt of an adequate saliva sample or samples. you can track the progress of your sample ( s ) on your dashboard. survey rounds : round 2 survey gift codes are issued and emailed within a few weeks of completion of all assigned surveys. if it has been a few weeks, and my amazon. com gift card code still has not arrived then please first check your spark dashboard for any updates on the status of your amazon. com gift card code. please email info @ sparkforautism. org if you have additional questions. if you received a $ 25 amazon. com gift card code instead of a $ 50 code for your saliva sample ( s ), it is because someone you invited to participate did not return a complete saliva sample. if you have further questions about this, please review the data consent form found in the “ my documents ” section of your dashboard or contact info @ sparkforautism. org. to redeem the amazon. com gift card code you must first have an amazon account. if you don't have an account with amazon, you can set one up here. once you are logged in to amazon, you can redeem your code by clicking on “ accounts and lists ” then “ your account ” near the upper right corner of the page. you will then be directed to a new page where you will click on “ gift cards ”. a new page will open where you can redeem a gift card. after you click on “ redeem a gift card ”, you will be directed to a new page. on this page you will enter the alphanumeric 14 - character code that you received in the email from spark. click “ apply to your balance ”. you will now have the funds available to make any purchase on amazon. i am having trouble with my amazon. com gift card code then amazon has a helpful page with tips for resolving gift card redemption problems. spark uses saliva to collect data as saliva samples offer a convenient method for dna collection as compared with other sources of dna, such as a cheek swab or blood samples. saliva collection is a common method for research ranging from large scientific studies to individual personalized medicine tests. we need saliva from beyond child or adult with asd as we are more likely to discover information about autism if we can compare an individual ’ s dna with the dna of their biological relatives. saliva kits are shipped to [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] purchase on amazon. i am having trouble with my amazon. com gift card code then amazon has a helpful page with tips for resolving gift card redemption problems. spark uses saliva to collect data as saliva samples offer a convenient method for dna collection as compared with other sources of dna, such as a cheek swab or blood samples. saliva collection is a common method for research ranging from large scientific studies to individual personalized medicine tests. we need saliva from beyond child or adult with asd as we are more likely to discover information about autism if we can compare an individual ’ s dna with the dna of their biological relatives. saliva kits are shipped to each address that you provide during registration. as a reminder, kits can be shipped only within the u. s. individuals who are stationed overseas in the military should use their current fpo or apo address. yes you can give multiple shipping addresses for different participants. we will ship saliva kits to multiple addresses you give us at registration. if your saliva kit has not arrived then, after you enroll in spark, it will take two to three weeks for the kit ( s ) to be delivered to the address ( es ) you provided. please periodically check your spark dashboard for any updates during that time. if you notice an error, please double - check that your address is given correctly. if you need to make changes to your address, you can do so by visiting your spark dashboard. if you have not received your kit after three weeks, please contact info @ sparkforautism. org. if your saliva collection kit is damaged or items are missing, please contact info @ sparkforautism. org. we only ship saliva kits to addresses within the united states. individuals who are stationed overseas in the military should use their current fpo or apo address. if you received the saliva kit in the mail to use the kit and provide saliva samples you follow the directions in the saliva collection box will take you step by step through the collection process. you and / or your child should not eat or drink for 30 minutes before spitting. tips for parents : hold the tube to your child ’ s mouth, or if your child is able, allow them to hold the tube and ask them to spit into it. if your child holds the tube, don ’ t let the saliva spill. you must get enough saliva, without air bubbles, to fill the tube to the line that is marked on the tube. this will likely require spitting multiple times. if you are having a [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] and provide saliva samples you follow the directions in the saliva collection box will take you step by step through the collection process. you and / or your child should not eat or drink for 30 minutes before spitting. tips for parents : hold the tube to your child ’ s mouth, or if your child is able, allow them to hold the tube and ask them to spit into it. if your child holds the tube, don ’ t let the saliva spill. you must get enough saliva, without air bubbles, to fill the tube to the line that is marked on the tube. this will likely require spitting multiple times. if you are having a hard time, we suggest giving yourself or your child a break for a few minutes in between spitting. then spit or ask your child to spit into the tube again. feel free to continue taking breaks and having them try again until you have collected enough saliva to get up to the line. during these breaks, it is important to not close the tube, so that the preserving liquid does not release and mix with the saliva just yet. we know the saliva collection can be challenging, but we appreciate your patience and continued efforts. for more detailed information on the saliva collection kit instructions — including what to do if you cannot get your child to spit into the tube — please email info @ sparkforautism. org. completing the saliva collection can be difficult for many people. you will find a helpful instructional video to walk you through the saliva collection process. the instructions that came in the box also include a section for if you and / or your child cannot spit. additionally, if you and / or your child ( ren ) are unable to collect saliva by spitting or using the sponge – we are working on providing alternative collection methods. these would include blood draws and cheek swabs, and we will contact participants when these become available. after completing saliva collection, please return your sample in the postage - paid box the kit came in. you can drop it in the mail or hand it to a usps mail delivery person. the postage - paid return label is already attached to the bottom of the box. when you send your saliva sample back, we will keep your saliva sample in a secure laboratory, and if it passes quality control, we will extract dna from it. research staff may separate the samples into smaller amounts and freeze them, so they will be available for research for an indefinite period of time. the samples will be stripped of your personal identifying information and labeled with a unique [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] completing saliva collection, please return your sample in the postage - paid box the kit came in. you can drop it in the mail or hand it to a usps mail delivery person. the postage - paid return label is already attached to the bottom of the box. when you send your saliva sample back, we will keep your saliva sample in a secure laboratory, and if it passes quality control, we will extract dna from it. research staff may separate the samples into smaller amounts and freeze them, so they will be available for research for an indefinite period of time. the samples will be stripped of your personal identifying information and labeled with a unique study identification number. spark is protecting my data as : all research data that could identify you or your child is replaced with a study code called a global unique identifier ( guid ). guids allow researchers to share data about you without sharing anything that could identify you. all your research data and records are stored electronically in a secure, encrypted, password - protected database. we will not release research data about you or your child to others, unless required by law. we will never publish anything about the study on any forum that could identify you without your express permission. our third - party service providers and consultants are legally required to keep all your research data private. while we cannot guarantee total privacy, we make every effort to maintain your privacy. your research data will never be shared with third parties without your consent. when you join spark, you allow the simons foundation autism research initiative ( sfari ) to share your research data with the national database for autism research ( ndar ). ndar is a central research data source for autism researchers from around the country. data in ndar is stored without any information that could identify you. before any of your research data from spark is shared for other autism research, all information that could identify you is replaced with a global unique identifier ( guid ). guids allow researchers to share research data about you without exposing anything that could identify you. to learn more about guids, contact info @ sparkforautism. org. on the date you withdraw from spark, we will stop asking for your research data and sharing it with other studies. any data that has already been shared with or used by other studies cannot be taken back. if you would like to withdraw from spark, please send an email to info @ sparkforautism. org. spark collects two main types of data : [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP], all information that could identify you is replaced with a global unique identifier ( guid ). guids allow researchers to share research data about you without exposing anything that could identify you. to learn more about guids, contact info @ sparkforautism. org. on the date you withdraw from spark, we will stop asking for your research data and sharing it with other studies. any data that has already been shared with or used by other studies cannot be taken back. if you would like to withdraw from spark, please send an email to info @ sparkforautism. org. spark collects two main types of data : information that participants share through surveys and the dna data that comes from participants ’ saliva samples. both types of information are stored securely and are encrypted, for an extra layer of protection. identifying information like names, phone numbers or email addresses is not shared with anyone outside the research study. identifying information is only shared with researchers who are using spark data for research. you are in control of the information you share. we will not share your data without your permission. if you choose to participate in a study, we will share your contact information with researchers so that they can contact you. after your dna has been sequenced, we will keep your saliva sample in a secure laboratory. if we have received enough dna, research staff may separate the samples into smaller amounts and freeze them, so they will be available for research for an indefinite period of time. the samples will be stripped of your personal identifying information and labeled with a unique study identification number. dna sequencing decodes the genetic letters that make up an individual ’ s genome. spark only looks at the portion of dna that codes for proteins, because most genetic differences related to autism are found in this part of an individual ’ s dna. the information generated from spark ’ s sequencing analysis cannot be used to determine a person ’ s identity. all sequencing data is stored securely in the spark database. researchers who request access to spark ’ s genetic data must also agree to store this information securely and may only use it for scientific purposes that they designate in their request. from the dna that is provided to spark, the genetic information we generate is stored securely in the spark database. spark and affiliated scientists analyze this information to better understand the genetic components of autism. sometimes the results of this research will appear in scientific journals. the information that appears in these journals cannot be used to expose an individual ’ s identity. spark study staff and [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] analysis cannot be used to determine a person ’ s identity. all sequencing data is stored securely in the spark database. researchers who request access to spark ’ s genetic data must also agree to store this information securely and may only use it for scientific purposes that they designate in their request. from the dna that is provided to spark, the genetic information we generate is stored securely in the spark database. spark and affiliated scientists analyze this information to better understand the genetic components of autism. sometimes the results of this research will appear in scientific journals. the information that appears in these journals cannot be used to expose an individual ’ s identity. spark study staff and researchers from around the world depend on dna from spark. outside researchers must go through an approval process before they are allowed to access spark ’ s dna database. it is possible that the vendors we work with ( for example, a company that hosts a spark survey ) could identify participants from their data. however, all of our vendors sign privacy agreements and are required by law to abide by these agreements. your contact information will not be shared with researchers through spark ’ s research matching program unless you give us permission. spark does not and will never sell data or dna to anyone. all information shared with spark is kept securely in its database. only if you request and receive a genetic result from spark will this information go into your medical record. only with your permission will the doctor have access to information that you share with spark. the only doctor who will receive information from spark will be the one you designate to receive the genetic result should a genetic result be available. the federal genetic information nondiscrimination act ( gina ) makes it illegal for employers, health insurers and group health plans to discriminate against individuals based on their genetic information. however, if you do receive a genetic result through spark, the physician you designated will put this information into your medical record, and there may be insurance implications. no other family members can see information that you enter as a spark participant. all participants over the age of 18 are required to have their own accounts. spark verifies participants identify by requiring that each individual who registers has a unique email address. the police or fbi does not have access to dna or other information collected. to protect your privacy, we have obtained a certificate of confidentiality from the national institutes of mental health. researchers can use this certificate to legally refuse to disclose information that may identify you in any federal, state or local civil, criminal, administrative [SEP]\n",
            "[CLS] what is the purpose of spark? [SEP] will put this information into your medical record, and there may be insurance implications. no other family members can see information that you enter as a spark participant. all participants over the age of 18 are required to have their own accounts. spark verifies participants identify by requiring that each individual who registers has a unique email address. the police or fbi does not have access to dna or other information collected. to protect your privacy, we have obtained a certificate of confidentiality from the national institutes of mental health. researchers can use this certificate to legally refuse to disclose information that may identify you in any federal, state or local civil, criminal, administrative, legislative or other proceedings — for example, if there is a court subpoena. researchers will use the certificate to resist any demands for information that would identify you, except as explained below : the certificate cannot be used to resist a demand for information from personnel of the united states federal or state government agency sponsoring the project and that will be used for auditing or program evaluation of agency - funded projects or for information that must be disclosed in order to meet the requirements of the federal food and drug administration. the certificate does not prevent you or a member of your family from voluntarily releasing information about your child, yourself or your involvement in this research. if an insurer or employer learns about you and / or your child ’ s participation and obtains your consent to receive research information, then the investigator may not use the certificate of confidentiality to withhold this information. [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHva2JOlpEFq",
        "outputId": "6f21e851-2994-4285-d327-cfadb89c19bb"
      },
      "source": [
        "sequence_ids = tokenized_example.sequence_ids()\n",
        "answers = new_file\n",
        "start_char = 0\n",
        "end_char = start_char + len(answers)\n",
        "print(end_char)\n",
        "# Start token index of the current span in the text.\n",
        "token_start_index = 0\n",
        "while sequence_ids[token_start_index] != 1:\n",
        "    token_start_index += 1\n",
        "\n",
        "# End token index of the current span in the text.\n",
        "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
        "while sequence_ids[token_end_index] != 1:\n",
        "    token_end_index -= 1\n",
        "\n",
        "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "offsets = tokenized_example[\"offset_mapping\"][0]\n",
        "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
        "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "        print(token_start_index)\n",
        "        token_start_index += 1\n",
        "    start_position = token_start_index - 1\n",
        "    while offsets[token_end_index][1] >= end_char:\n",
        "        token_end_index -= 1\n",
        "    end_position = token_end_index + 1\n",
        "    print(start_position, end_position)\n",
        "else:\n",
        "   print(\"The answer is not in this feature.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31987\n",
            "The answer is not in this feature.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3VhnwCsrwI1",
        "outputId": "cccb6fde-e31f-415d-8600-8d2e8bc056d9"
      },
      "source": [
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "input_ids = tokenizer.encode(\"What is the purpose of Spark?\", new_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (6295 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ny-oETstpi"
      },
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "# Search the input_ids for the first instance of the `[SEP]` token.\n",
        "sep_index = input_ids.index(tokenizer.sep_token_id)\n",
        "\n",
        "# The number of segment A tokens includes the [SEP] token istelf.\n",
        "num_seg_a = sep_index + 1\n",
        "\n",
        "# The remainder are segment B.\n",
        "num_seg_b = len(input_ids) - num_seg_a\n",
        "\n",
        "# Construct the list of 0s and 1s.\n",
        "segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
        "\n",
        "# There should be a segment_id for every input token.\n",
        "assert len(segment_ids) == len(input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "zcZrYOuxs-HM",
        "outputId": "cd709731-0356-4478-a1ea-bcde25517e6b"
      },
      "source": [
        "# !pip3 uninstall torch\n",
        "!pip3 install torch\n",
        "import torch\n",
        "# Run our example through the model.\n",
        "start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
        "                                 torch.tensor([segment_ids]),\n",
        "                                 return_dict = False) # The segment IDs to differentiate question from answer_text\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-62aaa04fd953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n\u001b[1;32m      6\u001b[0m                                  \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                  return_dict = False) # The segment IDs to differentiate question from answer_text\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         )\n\u001b[1;32m    711\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistilbert_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# (bs, max_query_len, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         return self.transformer(\n\u001b[1;32m    482\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mword_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m  \u001b[0;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.embedding(\n\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    }
  ]
}